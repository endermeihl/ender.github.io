**感知器学习规则**

---

### 感知器模型

感知器模型用于解决线性可分的二分类问题，其数学表达式为：

\[
y = f(w \cdot x + b)
\]

- **\( w \)**：权重向量。
- **\( x \)**：输入特征向量。
- **\( b \)**：偏置。
- **\( y \)**：感知器输出。
- **\( f \)**：激活函数（通常是阶跃函数或符号函数）。

**激活函数 \( f(z) \)** ：

\[
f(z) = 
\begin{cases}
1, & \text{如果 } z \geq 0 \\
-1, & \text{如果 } z < 0
\end{cases}
\]

---

### 感知器学习规则的步骤

1. **初始化权重**：
   - 将权重向量 \( w \) 和偏置 \( b \) 初始化为较小的随机值或零。

2. **对每个数据点进行预测**：
   - 计算感知器输出 \( y = f(w \cdot x + b) \)，其中 \( x \) 是输入，\( y \) 是感知器输出。

3. **更新权重**（如果预测错误）：
   - 如果 \( y_{\text{pred}} \neq y_{\text{true}} \)（预测值与真实值不符），更新权重和偏置：
     \[
     w = w + \eta \cdot (y_{\text{true}} - y_{\text{pred}}) \cdot x
     \]
     \[
     b = b + \eta \cdot (y_{\text{true}} - y_{\text{pred}})
     \]
     其中：
     - \( \eta \) 是学习率，控制权重更新的步长。
     - \( y_{\text{true}} \) 是真实标签。
     - \( y_{\text{pred}} \) 是模型的预测输出。

4. **重复迭代**：
   - 对所有训练数据重复上述过程，直到模型对所有数据分类正确，或达到最大迭代次数。

---

### 感知器学习规则的核心思想

感知器学习规则是基于误差驱动的更新过程。通过不断调整权重来减少模型的分类错误。对于**线性可分**的数据集，感知器学习算法可以在有限次迭代内收敛，即找到一个能正确分类所有训练数据的超平面。

---

### 示例

假设有以下训练数据：

| 样本 | \( x_1 \) | \( x_2 \) | 真实标签 \( y_{\text{true}} \) |
| ---- | --------- | --------- | ------------------------------ |
| 1    | 1         | 1         | 1                              |
| 2    | -1        | -1        | -1                             |
| 3    | 1         | -1        | -1                             |
| 4    | -1        | 1         | -1                             |

- 初始权重：\( w = [0, 0] \)，偏置 \( b = 0 \)，学习率 \( \eta = 0.1 \)。
- 通过多轮迭代，感知器模型将更新权重和偏置，使其能够正确分类所有样本。

---

### 结论

感知器学习规则通过简单的误差反馈机制调整权重，是解决线性可分问题的有效算法。尽管它无法处理非线性问题，但作为最早的神经网络模型之一，它为后续复杂的神经网络技术奠定了基础。